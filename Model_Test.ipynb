{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import collections\n",
    "import string\n",
    "import pickle\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from profanity_check import predict, predict_prob\n",
    "\n",
    "df = pd.read_csv(\"train_cleaned.csv\");\n",
    "#df = df.drop(columns=[\"index\"])\n",
    "#df.to_csv(\"train_cleaned.csv\", index=False)\n",
    "target = df['toxic']\n",
    "df = df.drop(columns=[\"toxic\"])\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, target, test_size=0.25, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\humza\\AppData\\Local\\conda\\conda\\envs\\Convergent\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "score:0.9043942546311383\n",
      "f_score:0.5993697478991596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\humza\\AppData\\Local\\conda\\conda\\envs\\Convergent\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score = model.score(x_test, y_test)\n",
    "print(\"LogisticRegression:\")\n",
    "print(\"score:\"+str(score))\n",
    "print(\"f_score:\"+str(f1_score(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier:\n",
      "score:0.9037174441631364\n",
      "f_score:0.003631647211413749\n"
     ]
    }
   ],
   "source": [
    "#MLP MLPClassifier\n",
    "model = MLPClassifier(solver='lbfgs', alpha=1e-2,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score = model.score(x_test, y_test)\n",
    "print(\"MLPClassifier:\")\n",
    "print(\"score:\"+str(score))\n",
    "print(\"f_score:\"+str(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC MLPClassifier\n",
    "model = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score = model.score(x_test, y_test)\n",
    "print(\"SVCClassifier:\")\n",
    "print(\"score:\"+str(score))\n",
    "print(\"f_score:\"+str(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\humza\\AppData\\Local\\conda\\conda\\envs\\Convergent\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier:\n",
      "score:0.9048955957185472\n",
      "f_score:0.03803245436105476\n"
     ]
    }
   ],
   "source": [
    "#SGDC lassifier\n",
    "model = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5,class_weight = \"balanced\")\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score = model.score(x_test, y_test)\n",
    "print(\"SGDClassifier:\")\n",
    "print(\"score:\"+str(score))\n",
    "print(\"f_score:\"+str(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFCClassifier:\n",
      "score:0.9534755470884616\n",
      "f_score:0.7210700330628195\n"
     ]
    }
   ],
   "source": [
    "#RF Classifier\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score = model.score(x_test, y_test)\n",
    "print(\"RFCClassifier:\")\n",
    "print(\"score:\"+str(score))\n",
    "print(\"f_score:\"+str(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFCClassifier:\n",
      "score:0.9521971273155692\n",
      "f_score:0.7088994046710426\n"
     ]
    }
   ],
   "source": [
    "#RF Classifier\n",
    "model = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "score = model.score(x_test, y_test)\n",
    "print(\"RFCClassifier:\")\n",
    "print(\"score:\"+str(score))\n",
    "print(\"f_score:\"+str(f1_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.09564\ttest-error:0.096458\n",
      "Multiple eval metrics have been passed: 'test-error' will be used for early stopping.\n",
      "\n",
      "Will train until test-error hasn't improved in 20 rounds.\n",
      "[1]\ttrain-error:0.09564\ttest-error:0.096458\n",
      "[2]\ttrain-error:0.068049\ttest-error:0.068082\n",
      "[3]\ttrain-error:0.052967\ttest-error:0.053468\n",
      "[4]\ttrain-error:0.051246\ttest-error:0.051438\n",
      "[5]\ttrain-error:0.049575\ttest-error:0.049808\n",
      "[6]\ttrain-error:0.048363\ttest-error:0.048806\n",
      "[7]\ttrain-error:0.046976\ttest-error:0.048054\n",
      "[8]\ttrain-error:0.046358\ttest-error:0.047678\n",
      "[9]\ttrain-error:0.045932\ttest-error:0.047352\n",
      "[10]\ttrain-error:0.045564\ttest-error:0.047026\n",
      "[11]\ttrain-error:0.04543\ttest-error:0.0467\n",
      "[12]\ttrain-error:0.045372\ttest-error:0.046349\n",
      "[13]\ttrain-error:0.045297\ttest-error:0.046449\n",
      "[14]\ttrain-error:0.044996\ttest-error:0.046625\n",
      "[15]\ttrain-error:0.04487\ttest-error:0.04655\n",
      "[16]\ttrain-error:0.04477\ttest-error:0.046524\n",
      "[17]\ttrain-error:0.044578\ttest-error:0.046224\n",
      "[18]\ttrain-error:0.044528\ttest-error:0.046249\n",
      "[19]\ttrain-error:0.044294\ttest-error:0.046274\n",
      "[20]\ttrain-error:0.04421\ttest-error:0.046349\n",
      "[21]\ttrain-error:0.044169\ttest-error:0.046249\n",
      "[22]\ttrain-error:0.044194\ttest-error:0.046073\n",
      "[23]\ttrain-error:0.044035\ttest-error:0.046148\n",
      "[24]\ttrain-error:0.04396\ttest-error:0.046199\n",
      "[25]\ttrain-error:0.043834\ttest-error:0.046224\n",
      "[26]\ttrain-error:0.043734\ttest-error:0.046098\n",
      "[27]\ttrain-error:0.043584\ttest-error:0.046123\n",
      "[28]\ttrain-error:0.043508\ttest-error:0.046148\n",
      "[29]\ttrain-error:0.043458\ttest-error:0.046199\n",
      "[30]\ttrain-error:0.043383\ttest-error:0.046148\n",
      "[31]\ttrain-error:0.043249\ttest-error:0.046123\n",
      "[32]\ttrain-error:0.043191\ttest-error:0.046174\n",
      "[33]\ttrain-error:0.043132\ttest-error:0.046123\n",
      "[34]\ttrain-error:0.043074\ttest-error:0.046148\n",
      "[35]\ttrain-error:0.042965\ttest-error:0.046023\n",
      "[36]\ttrain-error:0.04289\ttest-error:0.046023\n",
      "[37]\ttrain-error:0.042807\ttest-error:0.046123\n",
      "[38]\ttrain-error:0.042731\ttest-error:0.046199\n",
      "[39]\ttrain-error:0.04279\ttest-error:0.046199\n",
      "[40]\ttrain-error:0.042673\ttest-error:0.046174\n",
      "[41]\ttrain-error:0.042648\ttest-error:0.046098\n",
      "[42]\ttrain-error:0.042606\ttest-error:0.046148\n",
      "[43]\ttrain-error:0.042573\ttest-error:0.046098\n",
      "[44]\ttrain-error:0.042481\ttest-error:0.046023\n",
      "[45]\ttrain-error:0.042464\ttest-error:0.046023\n",
      "[46]\ttrain-error:0.04238\ttest-error:0.046023\n",
      "[47]\ttrain-error:0.042314\ttest-error:0.045973\n",
      "[48]\ttrain-error:0.042288\ttest-error:0.046048\n",
      "[49]\ttrain-error:0.04223\ttest-error:0.046174\n",
      "[50]\ttrain-error:0.042213\ttest-error:0.046148\n",
      "[51]\ttrain-error:0.042096\ttest-error:0.046048\n",
      "[52]\ttrain-error:0.042013\ttest-error:0.046148\n",
      "[53]\ttrain-error:0.042004\ttest-error:0.046224\n",
      "[54]\ttrain-error:0.041963\ttest-error:0.046098\n",
      "[55]\ttrain-error:0.041912\ttest-error:0.046048\n",
      "[56]\ttrain-error:0.041912\ttest-error:0.046073\n",
      "[57]\ttrain-error:0.041912\ttest-error:0.046023\n",
      "[58]\ttrain-error:0.041862\ttest-error:0.046048\n",
      "[59]\ttrain-error:0.041704\ttest-error:0.045998\n",
      "[60]\ttrain-error:0.041603\ttest-error:0.046148\n",
      "[61]\ttrain-error:0.041511\ttest-error:0.046174\n",
      "[62]\ttrain-error:0.041428\ttest-error:0.046174\n",
      "[63]\ttrain-error:0.041411\ttest-error:0.046224\n",
      "[64]\ttrain-error:0.041411\ttest-error:0.046199\n",
      "[65]\ttrain-error:0.041344\ttest-error:0.046199\n",
      "[66]\ttrain-error:0.041319\ttest-error:0.046249\n",
      "[67]\ttrain-error:0.041311\ttest-error:0.046199\n",
      "Stopping. Best iteration:\n",
      "[47]\ttrain-error:0.042314\ttest-error:0.045973\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#XGB\n",
    "param = {}\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eta'] = 0.15 #0.1\n",
    "param['max_depth'] = 6#6\n",
    "param['silent'] = 1\n",
    "param['eval_metric'] = 'error'#'logloss'#'auc'\n",
    "#param['min_child_weight'] = 1\n",
    "#param['subsample'] = 0.7\n",
    "#param['colsample_bytree'] = 0.7\n",
    "param['seed'] = 2019 #2017\n",
    "#added\n",
    "param['base_score'] = np.mean(y_train)#0.99 \n",
    "#param['scale_pos_weight']= 0.3\n",
    "#param['booster']= 'dart'\n",
    "num_rounds = 500\n",
    "plst = list(param.items())\n",
    "#model = xg_reg = xgb.XGBClassifier()\n",
    "\n",
    "#model.fit(x_train,y_train)\n",
    "xgtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "xgtest = xgb.DMatrix(x_test, label=y_test)\n",
    "watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[35669   376]\n",
      " [ 1458  2390]]\n",
      "XGB:\n",
      "accuracy:0.9540270222846113\n",
      "recall:0.8053352329569559\n",
      "precision:0.9123965090530459\n",
      "f_score:0.8555294603888965\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(xgb.DMatrix(x_test, label = y_test),ntree_limit = model.best_ntree_limit)\n",
    "cm = confusion_matrix(y_test, (y_pred>0.5))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "recall = np.mean(recall)\n",
    "precision = np.mean(precision)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"XGB:\")\n",
    "print(\"accuracy:\" + str((cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])))\n",
    "print(\"recall:\"+str(recall))\n",
    "#score = model.score(x_test, y_test)\n",
    "print(\"precision:\"+str(precision))\n",
    "print(\"f_score:\"+str(f1_score))\n",
    "#fig, ax = plt.subplots(figsize=(100, 100))\n",
    "#xgb.plot_tree(model, num_trees=4, ax=ax)\n",
    "#plt.show()\n",
    "#plt.savefig(\"temp.pdf\")\n",
    "#xgb.plot_tree(model, num_trees=0)\n",
    "#fig = plt.gcf()\n",
    "#fig.set_size_inches(300, 200)\n",
    "#fig.savefig('tree.png')\n",
    "#fig.savefig(\"shap.svg\", format='svg', dpi=1000, bbox_inches='tight')\n",
    "#fig.savefig(\"shap.pdf\", format='pdf', dpi=1000, bbox_inches='tight')\n",
    "#fig, ax = plt.subplots(figsize=(12,18))\n",
    "#xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( model, open( \"SGB_model.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
